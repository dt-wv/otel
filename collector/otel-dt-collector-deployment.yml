---
# required for k8sattributes processor
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: otel-collector
rules:
- apiGroups: ["","apps"]
  resources: ["pods", "namespaces","replicasets"]
  verbs: ["get", "watch", "list"]
---
# required for k8sattributes processor
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
   name: otel-collector
subjects:
- kind: ServiceAccount
  name: otel-collector-collector
  namespace: otel-backend
roleRef:
   kind: ClusterRole
   name: otel-collector
   apiGroup: rbac.authorization.k8s.io
---
apiVersion: v1
kind: Secret
metadata:
  name: dynatrace-secrets
  namespace: otel-backend
type: Opaque
stringData:
  # replace the my-environment-id and my-token-value with the right values
  environment-id: "my-environment-id"
  api-token: "my-token-value"
---
apiVersion: opentelemetry.io/v1alpha1
kind: OpenTelemetryCollector
metadata:
  name: otel-collector
  namespace: otel-backend
spec:
  # using the Dynatrace supported otel-collector
  image: ghcr.io/dynatrace/dynatrace-otel-collector/dynatrace-otel-collector:latest
  # using daemonset for a collector on every k8s node to get the logs
  mode: daemonset # deployment, statefulset, daemonset, sidecar
  env:
    - name: environment_id
      valueFrom:
        secretKeyRef:
          name: dynatrace-secrets
          key: environment-id
    - name: API_TOKEN
      valueFrom:
        secretKeyRef:
           name: dynatrace-secrets
           key: api-token
    - name: MY_POD_IP
      valueFrom:
        fieldRef:
           fieldPath: status.podIP
  autoscaler:
    targetCPUUtilization: 90
    minReplicas: 1
    maxReplicas: 5
  volumeMounts:
  - mountPath: /var/log
    name: varlog
    readOnly: true
  volumes:
  - name: varlog
    hostPath:
      path: /var/log
  config: |
    receivers:
   
      #scraping the telemetry from the otel-collector https://opentelemetry.io/docs/collector/configuration/#telemetry
      prometheus:
        config:
          scrape_configs:
          - job_name: otel-collector
            scrape_interval: 5s
            static_configs:
            - targets:
              - localhost:8888

      # Data sources: traces, metrics, logs
      otlp:
        protocols:
          grpc:
            endpoint: ${MY_POD_IP}:4317
          http:
            endpoint: ${MY_POD_IP}:4318
      
      # kubernetes pod log stout/sterror (this is not for logs written inside the pods)
      filelog:
        include:
          - /var/log/pods/*/*/*.log
        exclude:
          # Exclude logs from all containers named otel-collector
         #- /var/log/pods/*/*otel-collector*/*/*.log
        start_at: end
        include_file_path: true
        include_file_name: false
        operators:
          # Find out which format is used by kubernetes
          - type: router
            id: get-format
            routes:
              - output: parser-docker
                expr: 'body matches "^\\{"'
              - output: parser-crio
                expr: 'body matches "^[^ Z]+ "'
              - output: parser-containerd
                expr: 'body matches "^[^ Z]+Z"'
          # Parse CRI-O format
          - type: regex_parser
            id: parser-crio
            regex: '^(?P<time>[^ Z]+) (?P<stream>stdout|stderr) (?P<logtag>[^ ]*) ?(?P<log>.*)$'
            output: extract_metadata_from_filepath
            timestamp:
              parse_from: attributes.time
              layout_type: gotime
              layout: '2006-01-02T15:04:05.999999999Z07:00'
          # Parse CRI-Containerd format
          - type: regex_parser
            id: parser-containerd
            regex: '^(?P<time>[^ ^Z]+Z) (?P<stream>stdout|stderr) (?P<logtag>[^ ]*) ?(?P<log>.*)$'
            output: extract_metadata_from_filepath
            timestamp:
              parse_from: attributes.time
              layout: '%Y-%m-%dT%H:%M:%S.%LZ'
          # Parse Docker format
          - type: json_parser
            id: parser-docker
            output: extract_metadata_from_filepath
            timestamp:
              parse_from: attributes.time
              layout: '%Y-%m-%dT%H:%M:%S.%LZ'
          # Extract metadata from file path
          - type: regex_parser
            id: extract_metadata_from_filepath
            regex: '^.*\/(?P<namespace>[^_]+)_(?P<pod_name>[^_]+)_(?P<uid>[a-f0-9\-]{36})\/(?P<container_name>[^\._]+)\/(?P<restart_count>\d+)\.log$'
            parse_from: attributes["log.file.path"]
            cache:
              size: 128  # default maximum amount of Pods per Node is 110
          # Update body field after finishing all parsing
          - type: move
            from: attributes.log
            to: body
          # Rename attributes
          - type: move
            from: attributes.stream
            to: attributes["log.iostream"]
          - type: move
            from: attributes.container_name
            to: resource["k8s.container.name"]
          - type: move
            from: attributes.namespace
            to: resource["k8s.namespace.name"]
          - type: move
            from: attributes.pod_name
            to: resource["k8s.pod.name"]
          - type: move
            from: attributes.restart_count
            to: resource["k8s.container.restart_count"]
          - type: move
            from: attributes.uid
            to: resource["k8s.pod.uid"]


    processors:
      memory_limiter:
        check_interval: 1s
        limit_percentage: 75
        spike_limit_percentage: 25
      
      batch:
      
      transform:
        metric_statements:
          - context: metric
            statements:
              # Get count from the histogram. The new metric name will be <histogram_name>_count
              - extract_count_metric(true) where type == METRIC_DATA_TYPE_HISTOGRAM

              # Get sum from the histogram. The new metric name will be <histogram_name>_sum
              - extract_sum_metric(true) where type == METRIC_DATA_TYPE_HISTOGRAM
          - context: datapoint
            statements:
              # convert the <histogram_name>_sum metrics to gauges.
              - convert_sum_to_gauge() where IsMatch(metric.name, ".*_sum")

      filter/remove:
        error_mode: ignore
        metrics:
          metric:
            - 'type == METRIC_DATA_TYPE_HISTOGRAM'
            - 'IsMatch(name,"system.cpu.time")'
            - 'IsMatch(name,"system.disk.io")'
            - 'IsMatch(name,"system.disk.time")'
            - 'IsMatch(name,"system.disk.operations")'
            - 'IsMatch(name,"system.network.dropped_packets")'
            - 'IsMatch(name,"system.network.packets")'
            - 'IsMatch(name,"tomcat.global.received")'
            - 'IsMatch(name,"tomcat.sessions.rejected")'
            - 'IsMatch(name,"otelcol_http_server_request_size")'
            - 'IsMatch(name,"otelcol_exporter_sent_spans")'
            - 'IsMatch(name,"otelcol_receiver_refused_metric_points")'
            - 'IsMatch(name,"otelcol_processor_batch_timeout_trigger_send")'
            - 'IsMatch(name,"otelcol_http_client_request_size")'
                  
      # requires a clusterrole and clusterrolebinding -- see above
      k8sattributes:
        auth_type: "serviceAccount"
        passthrough: false
        extract:
          metadata:
            - k8s.pod.name
            - k8s.pod.uid
            - k8s.deployment.name
            - k8s.statefulset.name
            - k8s.daemonset.name
            - k8s.cronjob.name
            - k8s.namespace.name
            - k8s.node.name
            - k8s.pod.start_time
            - k8s.cluster.uid
          annotations:
            # extracts Keys & values of annotations matching regex `opentel.*` or `.*` for anything
            - key_regex: .* 
              from: pod
          labels:
            # extracts Keys & values of labels matching regex `opentel.*` or `.*` for anything
            - key_regex: .* 
              from: pod


    exporters:
      otlphttp/dynatrace:
         endpoint: "https://${environment_id}.live.dynatrace.com/api/v2/otlp"
         headers:
           Authorization: "Api-Token ${API_TOKEN}"
    

      #debugging output if required
      debug:  
        verbosity: detailed


    service:
      pipelines:
        traces:
          receivers: [otlp]
          processors: [memory_limiter, batch, k8sattributes]
          exporters: [otlphttp/dynatrace]
        metrics:
          receivers: [prometheus,otlp]
          processors: [memory_limiter, transform, batch, filter/remove]
          exporters: [otlphttp/dynatrace, debug]
        logs:
          receivers: [otlp, filelog]
          processors: [memory_limiter, batch]
          exporters: [otlphttp/dynatrace]
    
      # get the otel-collector telemetry https://opentelemetry.io/docs/collector/configuration/#telemetry
      telemetry:
        metrics:
          level: detailed
          address: localhost:8888
        logs:
          level: DEBUG
          initial_fields:
            service: otel-collector